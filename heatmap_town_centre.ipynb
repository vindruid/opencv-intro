{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "heatmap town centre.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN/QMLFENZoRZmeJ+TwKB8P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vindruid/opencv-intro/blob/master/heatmap_town_centre.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j_K8wJCIBNE",
        "colab_type": "text"
      },
      "source": [
        "# Download Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hde0p0CIL7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER8qAea6IMN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://drive.google.com/file/d/1sf85EueuGf5VDeHt7UAv2UHPIhEco_4f/view?usp=sharing\n",
        "file_id = '1sf85EueuGf5VDeHt7UAv2UHPIhEco_4f'\n",
        "path_video = 'video_town_centre.mp4'\n",
        "download_file_from_google_drive(file_id, destination)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJgsq0elJMZg",
        "colab_type": "text"
      },
      "source": [
        "source: http://www.robots.ox.ac.uk/ActiveVision/Research/Projects/2009bbenfold_headpose/Datasets/TownCentreXVID.avi\n",
        "\n",
        "we only use a part of whole video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7Q-2bSHNhm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # wait until the video completely downloaded\n",
        "# import time\n",
        "# time.sleep(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9F3qG-UI7ee",
        "colab_type": "text"
      },
      "source": [
        "# Show Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcltbXyEIvr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEhhR8ZsIVVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_video = os.path.join(\"video_town_centre.mp4\")\n",
        "mp4 = open(path_video,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ5d7dq_JAC7",
        "colab_type": "text"
      },
      "source": [
        "# Inspect Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffg6wtBvPZpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqWG5EJZPsWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_video = os.path.join(\"video_town_centre.mp4\")\n",
        "cap  = cv2.VideoCapture(path_video)\n",
        "\n",
        "_, img = cap.read()\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "count_frame = 1\n",
        "while img is not None: \n",
        "  count_frame += 1 \n",
        "  _, img = cap.read()\n",
        "\n",
        "print(\"TOTAL FRAME:\", count_frame)\n",
        "print(\"FPS:\", fps)\n",
        "print(\"Width:\", w)\n",
        "print(\"Height:\", h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhTg2eFVP1VB",
        "colab_type": "text"
      },
      "source": [
        "# Heat Map Static (Write to Image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o88xiLz4VVJ-",
        "colab_type": "text"
      },
      "source": [
        "source: https://github.com/intel-iot-devkit/python-cv-samples/tree/master/examples/motion-heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCxeIHUzQrcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CGyJi_pQweO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap = cv2.VideoCapture(path_video)\n",
        "# pip install opencv-contrib-python\n",
        "fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
        "\n",
        "# number of frames is a variable for development purposes, you can change the for loop to a while(cap.isOpened()) instead to go through the whole video\n",
        "num_frames = 350\n",
        "\n",
        "first_iteration_indicator = 1\n",
        "for i in range(0, num_frames):\n",
        "    '''\n",
        "    There are some important reasons this if statement exists:\n",
        "        -in the first run there is no previous frame, so this accounts for that\n",
        "        -the first frame is saved to be used for the overlay after the accumulation has occurred\n",
        "        -the height and width of the video are used to create an empty image for accumulation (accum_image)\n",
        "    '''\n",
        "    if (first_iteration_indicator == 1):\n",
        "        ret, frame = cap.read()\n",
        "        first_frame = copy.deepcopy(frame)\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        height, width = gray.shape[:2]\n",
        "        accum_image = np.zeros((height, width), np.uint8)\n",
        "        first_iteration_indicator = 0\n",
        "    else:\n",
        "        ret, frame = cap.read()  # read a frame\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # convert to grayscale\n",
        "\n",
        "        fgmask = fgbg.apply(gray)  # remove the background\n",
        "\n",
        "        # for testing purposes, show the result of the background subtraction\n",
        "        # cv2.imshow('diff-bkgnd-frame', fgmask)\n",
        "\n",
        "        # apply a binary threshold only keeping pixels above thresh and setting the result to maxValue.  If you want\n",
        "        # motion to be picked up more, increase the value of maxValue.  To pick up the least amount of motion over time, set maxValue = 1\n",
        "        thresh = 2\n",
        "        maxValue = 2\n",
        "        ret, th1 = cv2.threshold(fgmask, thresh, maxValue, cv2.THRESH_BINARY)\n",
        "        # for testing purposes, show the threshold image\n",
        "        # cv2.imwrite('diff-th1.jpg', th1)\n",
        "\n",
        "        # add to the accumulated image\n",
        "        accum_image = cv2.add(accum_image, th1)\n",
        "        # for testing purposes, show the accumulated image\n",
        "        # cv2.imwrite('diff-accum.jpg', accum_image)\n",
        "\n",
        "        # for testing purposes, control frame by frame\n",
        "        # raw_input(\"press any key to continue\")\n",
        "\n",
        "# apply a color map\n",
        "# COLORMAP_PINK also works well, COLORMAP_BONE is acceptable if the background is dark\n",
        "color_image = im_color = cv2.applyColorMap(accum_image, cv2.COLORMAP_HOT)\n",
        "# for testing purposes, show the colorMap image\n",
        "# cv2.imwrite('diff-color.jpg', color_image)\n",
        "\n",
        "# overlay the color mapped image to the first frame\n",
        "result_overlay = cv2.addWeighted(first_frame, 0.7, color_image, 0.7, 0)\n",
        "\n",
        "# save the final overlay image\n",
        "cv2.imwrite('diff-overlay.jpg', result_overlay)\n",
        "\n",
        "# cleanup\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6g3fGt8RCJ-",
        "colab_type": "text"
      },
      "source": [
        "# Heat Map Dinamic (Write to Video)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr4x5z3YVnWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time \n",
        "path_video = os.path.join(\"video_town_centre.mp4\")\n",
        "cap  = cv2.VideoCapture(path_video)\n",
        "\n",
        "_, img = cap.read()\n",
        "\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "path_heatmap = os.path.join('video_heatmap.mp4') \n",
        "vid_writer = cv2.VideoWriter(path_heatmap, cv2.VideoWriter_fourcc(*'MP4V'), fps, (W, H))\n",
        "\n",
        "fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
        "accum_image = np.zeros((H, W), np.uint8)\n",
        "# apply a binary threshold only keeping pixels above thresh and setting the result to maxValue.  If you want\n",
        "# motion to be picked up more, increase the value of maxValue.  To pick up the least amount of motion over time, set maxValue = 1\n",
        "thresh = 2\n",
        "maxValue = 2\n",
        "\n",
        "count_frame = 1\n",
        "while img is not None: \n",
        "\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    fgmask = fgbg.apply(gray)  # remove the background\n",
        "\n",
        "    _, th1 = cv2.threshold(fgmask, thresh, maxValue, cv2.THRESH_BINARY)\n",
        "\n",
        "    accum_image = cv2.add(accum_image, th1)\n",
        "\n",
        "    color_image = cv2.applyColorMap(accum_image, cv2.COLORMAP_HOT)\n",
        "    result_overlay = cv2.addWeighted(img, 0.7, color_image, 0.7, 0)\n",
        "\n",
        "    vid_writer.write(result_overlay)\n",
        "\n",
        "    count_frame += 1 \n",
        "    _, img = cap.read()\n",
        "\n",
        "    if count_frame % 100 == 0:\n",
        "        print(\"FRAME PROCESSED\",count_frame)\n",
        "\n",
        "vid_writer.release()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YERzWPg0X2jp",
        "colab_type": "text"
      },
      "source": [
        "# Compress Result Video "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6_cZ4ejX9gX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_compressed_heatmap = 'video_heatmap_c.mp4'\n",
        "os.system(f\"ffmpeg -i {path_heatmap} -vcodec libx264 {path_compressed_heatmap}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2jQYB2VYSRt",
        "colab_type": "text"
      },
      "source": [
        "# Show Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECcvjaj8YTZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show video\n",
        "mp4 = open(path_compressed_heatmap,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUWhZGjbiHfc",
        "colab_type": "text"
      },
      "source": [
        "# Resize Image before calculating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBQQREZwcEkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time \n",
        "path_video = os.path.join(\"video_town_centre.mp4\")\n",
        "cap  = cv2.VideoCapture(path_video)\n",
        "\n",
        "_, img = cap.read()\n",
        "\n",
        "H,W = 300, 400\n",
        "img = cv2.resize(img, (W,H), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
        "accum_image = np.zeros((H, W), np.uint8)\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "path_heatmap = os.path.join('video_heatmap_smaller.mp4') \n",
        "vid_writer = cv2.VideoWriter(path_heatmap, cv2.VideoWriter_fourcc(*'MP4V'), fps, (W, H))\n",
        "\n",
        "# apply a binary threshold only keeping pixels above thresh and setting the result to maxValue.  If you want\n",
        "# motion to be picked up more, increase the value of maxValue.  To pick up the least amount of motion over time, set maxValue = 1\n",
        "thresh = 2\n",
        "maxValue = 2\n",
        "\n",
        "count_frame = 1\n",
        "while img is not None: \n",
        "    img = cv2.resize(img, (W,H), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    fgmask = fgbg.apply(gray)  # remove the background\n",
        "\n",
        "    _, th1 = cv2.threshold(fgmask, thresh, maxValue, cv2.THRESH_BINARY)\n",
        "\n",
        "    accum_image = cv2.add(accum_image, th1)\n",
        "\n",
        "    color_image = cv2.applyColorMap(accum_image, cv2.COLORMAP_HOT)\n",
        "    result_overlay = cv2.addWeighted(img, 0.7, color_image, 0.7, 0)\n",
        "\n",
        "    vid_writer.write(result_overlay)\n",
        "\n",
        "    count_frame += 1 \n",
        "    _, img = cap.read()\n",
        "\n",
        "    if count_frame % 100 == 0:\n",
        "        print(\"FRAME PROCESSED\",count_frame)\n",
        "        break\n",
        "\n",
        "vid_writer.release()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "posigOnelDU_",
        "colab_type": "text"
      },
      "source": [
        "# Include Planar Map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jms4LTvlDKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # https://drive.google.com/file/d/1jb1DKrr52LrCp5RNgmq0UnIlVTDoYPro/view?usp=sharing\n",
        "# file_id = '1jb1DKrr52LrCp5RNgmq0UnIlVTDoYPro'\n",
        "# destination = 'road_icon.jpg'\n",
        "# download_file_from_google_drive(file_id, destination)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z5nZnlQl49O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_my_map = 'road_icon.jpg'\n",
        "my_map = cv2.imread(path_my_map)\n",
        "\n",
        "H,W = 300, 400\n",
        "my_map = cv2.resize(my_map, (W,H), interpolation = cv2.INTER_AREA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHEXd5gVl54N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_map.shape, my_map.max(), my_map.min(), my_map.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKYGVleYl5_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(cv2.cvtColor(my_map, cv2.COLOR_BGR2RGB) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOSSkYAylDPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_img = img.copy()\n",
        "H,W = 300, 400\n",
        "my_img = cv2.resize(my_img, (W,H), interpolation = cv2.INTER_AREA)\n",
        "plt.imshow(cv2.cvtColor(my_img, cv2.COLOR_BGR2RGB) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp-oqpzcrSDE",
        "colab_type": "text"
      },
      "source": [
        "## Draw Points for testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJrPxHzYt7uF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.imshow(my_img)\n",
        "ax2.imshow(my_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsIqthZbreAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_pts_img = [(0, 250), (175, 300), (230, 50), (325, 75)] # (W,H)\n",
        "list_pts_map = [(25, 75), (25, 220), (375,75), (375, 220)]\n",
        "list_colors = [(0,0,255), (0,255,0), (255,0,0), (255,0,255)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "358lkAESst2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_img_test = my_img.copy()\n",
        "my_map_test = my_map.copy()\n",
        "radius = 10\n",
        "thickness = -1 #full\n",
        "\n",
        "for idx in range(len(list_pts_img)):\n",
        "    pts_img = list_pts_img[idx]\n",
        "    pts_map = list_pts_map[idx]\n",
        "    color = list_colors[idx]\n",
        "\n",
        "    cv2.circle(my_img_test, pts_img, radius, color, thickness)  \n",
        "    cv2.circle(my_map_test, pts_map, radius, color, thickness)  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s7q7_pxtijJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.imshow(my_img_test)\n",
        "ax2.imshow(my_map_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7dAdZfhrR0i",
        "colab_type": "text"
      },
      "source": [
        "# Perspective"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5csjhWTSu0hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# provide points from image 1\n",
        "pts_src = np.array(list_pts_img)\n",
        "# corresponding points from image 2 (i.e. (154, 174) matches (212, 80))\n",
        "pts_dst = np.array(list_pts_map)\n",
        "\n",
        "# calculate matrix H\n",
        "h, status = cv2.findHomography(pts_src, pts_dst)\n",
        "\n",
        "# provide a point you wish to map from image 1 to image 2\n",
        "a = np.array(list_pts_img, dtype='float32')\n",
        "a = np.array([a])\n",
        "\n",
        "# finally, get the mapping\n",
        "pointsOut = cv2.perspectiveTransform(a, h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fddDBmnkvCwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a, a.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIr4VYJfu-Zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pointsOut, pointsOut.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNVqwkbvlDE7",
        "colab_type": "text"
      },
      "source": [
        "## Test New Points Perspective"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZWuEVhdwOtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.imshow(my_img_test)\n",
        "ax2.imshow(my_map_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgXwtQ5OwASz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_pts_img_new = [(150, 150), (325, 200)] # (W,H)\n",
        "list_colors_new = [(0,255,255), (255,255,0)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFUJXxswvNaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.array(list_pts_img_new, dtype='float32')\n",
        "a = np.array([a])\n",
        "list_pts_map_new_pred = cv2.perspectiveTransform(a, h)[0]\n",
        "list_pts_map_new_pred = np.array(list_pts_map_new_pred, dtype='int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRuK4TSSwiHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_pts_map_new_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T00lasZswh-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "radius = 10\n",
        "thickness = -1 #full\n",
        "\n",
        "for idx in range(len(list_pts_img_new)):\n",
        "    pts_img = tuple(list_pts_img_new[idx])\n",
        "    pts_map = tuple(list_pts_map_new_pred[idx])\n",
        "    color = list_colors_new[idx]\n",
        "\n",
        "    cv2.circle(my_img_test, pts_img, radius, color, thickness)  \n",
        "    cv2.circle(my_map_test, pts_map, radius, color, thickness)  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8q-jOmzvM67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "ax1.imshow(my_img_test)\n",
        "ax2.imshow(my_map_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClBetXkSxJtc",
        "colab_type": "text"
      },
      "source": [
        "# Project Mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsZdvvR9xJlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fgmask_test = fgmask.copy()\n",
        "fgmask_test = cv2.cvtColor(fgmask_test, cv2.COLOR_GRAY2BGR)  # convert to grayscale\n",
        "plt.imshow(fgmask_test, cmap = 'gray');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfCPbJDbxJfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask_adjusted = cv2.warpPerspective(fgmask_test, h, (400,300))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHwgsv1YxJZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,15))\n",
        "ax1.imshow(fgmask_test)\n",
        "ax2.imshow(mask_adjusted)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5SZX8MYZUHn",
        "colab_type": "text"
      },
      "source": [
        "# Coretan "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGUO5jzkdF4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7lR8YELcYJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fgmask.shape, fgmask.max(), fgmask.min(), fgmask.mean(), "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EorrWHW9cb10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(fgmask, cmap = 'gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFSZ7BU1geMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "th1.shape, th1.max(), th1.min(), th1.mean(), "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft_C6M-NjRb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(th1, cmap = 'gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gfjJOJ0dUyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accum_image.shape, accum_image.max(), accum_image.min(), accum_image.mean(), "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3aKzpU1gcwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(accum_image, cmap = 'gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kps_RZ4DjTSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}