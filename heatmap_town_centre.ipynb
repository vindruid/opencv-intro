{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "heatmap town centre.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO8pXuVL6dSPqhGmn2/bSbB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vindruid/opencv-intro/blob/master/heatmap_town_centre.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j_K8wJCIBNE",
        "colab_type": "text"
      },
      "source": [
        "# Download Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hde0p0CIL7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER8qAea6IMN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://drive.google.com/file/d/1sf85EueuGf5VDeHt7UAv2UHPIhEco_4f/view?usp=sharing\n",
        "file_id = '1sf85EueuGf5VDeHt7UAv2UHPIhEco_4f'\n",
        "path_video = 'video_town_centre.mp4'\n",
        "download_file_from_google_drive(file_id, destination)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJgsq0elJMZg",
        "colab_type": "text"
      },
      "source": [
        "source: http://www.robots.ox.ac.uk/ActiveVision/Research/Projects/2009bbenfold_headpose/Datasets/TownCentreXVID.avi\n",
        "\n",
        "we only use a part of whole video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7Q-2bSHNhm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # wait until the video completely downloaded\n",
        "# import time\n",
        "# time.sleep(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9F3qG-UI7ee",
        "colab_type": "text"
      },
      "source": [
        "# Show Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcltbXyEIvr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEhhR8ZsIVVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_video = os.path.join(\"video_town_centre.mp4\")\n",
        "mp4 = open(path_video,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ5d7dq_JAC7",
        "colab_type": "text"
      },
      "source": [
        "# Inspect Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffg6wtBvPZpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqWG5EJZPsWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_video = os.path.join(\"video_town_centre.mp4\")\n",
        "cap  = cv2.VideoCapture(path_video)\n",
        "\n",
        "_, img = cap.read()\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "count_frame = 1\n",
        "while img is not None: \n",
        "  count_frame += 1 \n",
        "  _, img = cap.read()\n",
        "\n",
        "print(\"TOTAL FRAME:\", count_frame)\n",
        "print(\"FPS:\", fps)\n",
        "print(\"Width:\", w)\n",
        "print(\"Height:\", h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhTg2eFVP1VB",
        "colab_type": "text"
      },
      "source": [
        "# Heat Map Static (Write to Image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o88xiLz4VVJ-",
        "colab_type": "text"
      },
      "source": [
        "source: https://github.com/intel-iot-devkit/python-cv-samples/tree/master/examples/motion-heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCxeIHUzQrcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CGyJi_pQweO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap = cv2.VideoCapture(path_video)\n",
        "# pip install opencv-contrib-python\n",
        "fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
        "\n",
        "# number of frames is a variable for development purposes, you can change the for loop to a while(cap.isOpened()) instead to go through the whole video\n",
        "num_frames = 350\n",
        "\n",
        "first_iteration_indicator = 1\n",
        "for i in range(0, num_frames):\n",
        "    '''\n",
        "    There are some important reasons this if statement exists:\n",
        "        -in the first run there is no previous frame, so this accounts for that\n",
        "        -the first frame is saved to be used for the overlay after the accumulation has occurred\n",
        "        -the height and width of the video are used to create an empty image for accumulation (accum_image)\n",
        "    '''\n",
        "    if (first_iteration_indicator == 1):\n",
        "        ret, frame = cap.read()\n",
        "        first_frame = copy.deepcopy(frame)\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        height, width = gray.shape[:2]\n",
        "        accum_image = np.zeros((height, width), np.uint8)\n",
        "        first_iteration_indicator = 0\n",
        "    else:\n",
        "        ret, frame = cap.read()  # read a frame\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # convert to grayscale\n",
        "\n",
        "        fgmask = fgbg.apply(gray)  # remove the background\n",
        "\n",
        "        # for testing purposes, show the result of the background subtraction\n",
        "        # cv2.imshow('diff-bkgnd-frame', fgmask)\n",
        "\n",
        "        # apply a binary threshold only keeping pixels above thresh and setting the result to maxValue.  If you want\n",
        "        # motion to be picked up more, increase the value of maxValue.  To pick up the least amount of motion over time, set maxValue = 1\n",
        "        thresh = 2\n",
        "        maxValue = 2\n",
        "        ret, th1 = cv2.threshold(fgmask, thresh, maxValue, cv2.THRESH_BINARY)\n",
        "        # for testing purposes, show the threshold image\n",
        "        # cv2.imwrite('diff-th1.jpg', th1)\n",
        "\n",
        "        # add to the accumulated image\n",
        "        accum_image = cv2.add(accum_image, th1)\n",
        "        # for testing purposes, show the accumulated image\n",
        "        # cv2.imwrite('diff-accum.jpg', accum_image)\n",
        "\n",
        "        # for testing purposes, control frame by frame\n",
        "        # raw_input(\"press any key to continue\")\n",
        "\n",
        "# apply a color map\n",
        "# COLORMAP_PINK also works well, COLORMAP_BONE is acceptable if the background is dark\n",
        "color_image = im_color = cv2.applyColorMap(accum_image, cv2.COLORMAP_HOT)\n",
        "# for testing purposes, show the colorMap image\n",
        "# cv2.imwrite('diff-color.jpg', color_image)\n",
        "\n",
        "# overlay the color mapped image to the first frame\n",
        "result_overlay = cv2.addWeighted(first_frame, 0.7, color_image, 0.7, 0)\n",
        "\n",
        "# save the final overlay image\n",
        "cv2.imwrite('diff-overlay.jpg', result_overlay)\n",
        "\n",
        "# cleanup\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6g3fGt8RCJ-",
        "colab_type": "text"
      },
      "source": [
        "# Heat Map Dinamic (Write to Video)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr4x5z3YVnWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time \n",
        "path_video = os.path.join(\"video_town_centre.mp4\")\n",
        "cap  = cv2.VideoCapture(path_video)\n",
        "\n",
        "_, img = cap.read()\n",
        "\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "path_heatmap = os.path.join('video_heatmap__.mp4') \n",
        "vid_writer = cv2.VideoWriter(path_heatmap, cv2.VideoWriter_fourcc(*'MP4V'), fps, (W, H))\n",
        "\n",
        "fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
        "accum_image = np.zeros((H, W), np.uint8)\n",
        "# apply a binary threshold only keeping pixels above thresh and setting the result to maxValue.  If you want\n",
        "# motion to be picked up more, increase the value of maxValue.  To pick up the least amount of motion over time, set maxValue = 1\n",
        "thresh = 2\n",
        "maxValue = 2\n",
        "\n",
        "count_frame = 1\n",
        "while img is not None: \n",
        "\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    fgmask = fgbg.apply(gray)  # remove the background\n",
        "\n",
        "    _, th1 = cv2.threshold(fgmask, thresh, maxValue, cv2.THRESH_BINARY)\n",
        "\n",
        "    accum_image = cv2.add(accum_image, th1)\n",
        "\n",
        "    color_image = cv2.applyColorMap(accum_image, cv2.COLORMAP_HOT)\n",
        "    result_overlay = cv2.addWeighted(img, 0.7, color_image, 0.7, 0)\n",
        "\n",
        "    vid_writer.write(result_overlay)\n",
        "\n",
        "    count_frame += 1 \n",
        "    _, img = cap.read()\n",
        "\n",
        "    if count_frame % 100 == 0:\n",
        "        print(\"FRAME PROCESSED\",count_frame)\n",
        "\n",
        "vid_writer.release()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YERzWPg0X2jp",
        "colab_type": "text"
      },
      "source": [
        "# Compress Result Video "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6_cZ4ejX9gX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_compressed_heatmap = 'video_heatmap_c.mp4'\n",
        "os.system(f\"ffmpeg -i {path_heatmap} -vcodec libx264 {path_compressed_heatmap}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2jQYB2VYSRt",
        "colab_type": "text"
      },
      "source": [
        "# Show Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECcvjaj8YTZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show video\n",
        "mp4 = open(path_compressed_heatmap,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5SZX8MYZUHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}